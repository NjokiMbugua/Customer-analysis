---
title: "Week-13-IP-unsupervised"
author: "Njoki Mbugua"
date: "7/9/2021"
output: html_document
---
```{r}
library(knitr)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Defining the Question
### a) Specifying the Question
The main objective of this project is to:
a).Perform clustering stating insights drawn from data analysis and visualizations.

b).Upon implementation, provide comparisons between modeling the approaches used i.e. K-Means clustering vs Hierarchical clustering highlighting the strengths and limitations of each approach in the context of your analysis. 

### b) Defining the Metric for Success
a).Exhaustively perform Exploratory Data Analysis (Univariate and bivariate analysis)

b). Come up with a model that best performs customer analysis for optimal results.

### c) Understanding the context
Working as a consultant Data scientist for Kira Plastinina to come up with the best model for customer analysis.Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

### d) Recording the experimental design
Importing and reading the data
Data Cleaning
Exploratory Data Analysis(Univariate and bivariate)
Implementing the solution( K-means and hierarchical clustering)
Conclusions and recommendations

### e) Data Relevance
For this project the ecommerce data set was used. can be found here [http://bit.ly/EcommerceCustomersDataset].  

Data Description

The dataset consists of 10 numerical and 8 categorical attributes.

The Revenue attribute can be used as the class label.

“Administrative”, “Administrative Duration”, “Informational”, “Informational Duration”, “Product Related” and “Product Related Duration” represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another.

The value of the Bounce Rate feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (“bounce”) without triggering any other requests to the analytics server during that session.

The value of the Exit Rate feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.

The Page Value feature represents the average value for a web page that a user visited before completing an e-commerce transaction.

The Special Day feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine’s Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8.

The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.


# Reading and previewing the dataset
```{r}
# Data url=http://bit.ly/EcommerceCustomersDataset

customer = read.csv('http://bit.ly/EcommerceCustomersDataset',na.strings = "")
```

```{r}
# previeving the top rows of the dataset
head(customer)
```

```{r}
# previewing the bottom rows of the dataset
tail(customer, n=5)
```

```{r}
# checking the class of the dataset
class(customer)
```

```{r}
# checcking the number of rows and columns
dim(customer)
```

```{r}
# Viewing the summary statistics of the data
summary(customer)
```
```{r}
# checking the structure of the data
str(customer)
```
```{r}
# previewing the column names
colnames(customer)
```
# Data cleaning
```{r}
#Checking for missing values in the dataframe

any(is.na(customer))
```

```{r}
# Checking the sum of missing values
colSums(is.na(customer))
```


```{r}
# Ommiting the missing values

df <- na.omit(customer)
```

```{r}
# confirming if null values have been eliminated
any(is.na(df))

# Missing values have been eliminated
```

```{r}
# Checking for duplicated values
sum(duplicated(df))

# There are no duplicated values in the dataframe
```

```{r}

library(dplyr)
distinct(df)
```

```{r}
# checking for outliers
# First Select numeric columns
df1 <- select_if(df, is.numeric)             
head(df1)
```

```{r}
# Using the boxplot to detect outliers in the numeric columns
boxplot(df1)
```
Outliers were detected in the product related column. However they were not removed as that may highly affect our analysis.
```{r}
# listing outliers
boxplot.stats(df1$ProductRelated_Duration)$out
```
# Exploratory Data Analysis
## Univariate analysis
### Measures of central tendency
```{r}
# previewing the numerical columns
colnames(df1)
```

```{r}
# Getting a summary of descriptive statistics
library(psych)
describe(df1)
```
### Univariate graphical EDA
```{r}
library(ggplot2)
```

```{r}
# Histogram of showing exit rates.
qplot(data=df1, x=df1$ExitRates, colour=I("blue"))
```
The exit rates were concentrated between 0 and 0.5. with an extreme observation of 0.20.
```{r}
# Histogram of showing distribution of page values.
qplot(data=df1, x=df1$PageValues, colour=I("blue"))
```
The distribution of page values ranged from 0 to 100 with the highest concentration being at zero.
```{r}
# Histogram of showing distribution of prouct related visits.
qplot(data=df1, x=df1$ProductRelated, colour=I("blue"))

```
The product related visit values were mostly concentrated between 0 and 200. 

## Bivariate analysis
```{r}
# bargraph showing Visitor types.
ggplot(data = df, aes(x = df$VisitorType)) +  geom_bar(fill = "#0073C2FF", color = 'cyan')
```
Majority of the visitors on the sites were return visitors. There was also a considerable number of new visitors.

```{r}
# # bargraph showing monthly site visits.
ggplot(data = df, aes(x = df$Month)) +  geom_bar(fill = "red", color = 'blue')

```
People were most active on the sites during the months of May followed closely by November then March and December.

```{r}
# Relationship between visitor type and revenue
ggplot(data = df) + 
	geom_point(aes(x = df$ProductRelated, y = df$VisitorType, color = df$Revenue ), size = 3, alpha = 0.6)
```

# Building the prediction models
## Hierarchical clustering

```{r}
head(df)
```


```{r}

str(df)
```


```{r}
# converting character columns to numeric
char_columns <- sapply(df, is.character)             # Identify character columns
df_chars_as_num <- df                             
# Replicate 
df_chars_as_num[ , char_columns] <- as.data.frame(apply(df_chars_as_num[ , char_columns], 2, as.numeric))  

sapply(df_chars_as_num, class) 
```
```{r}
df$VisitorType  <- as.numeric(as.logical(df$VisitorType))
df$Month   <- as.numeric(as.character(df$Month))
df$Weekend   <- as.numeric(as.logical(df$Weekend))

```

```{r}
str(df)
```

```{r}
# converting character columns to numeric
log_columns <- sapply(df, is.character)             # Identify character columns
df_chars_as_num <- df                             
# Replicate 
df_chars_as_num[ , char_columns] <- as.data.frame(apply(df_chars_as_num[ , char_columns], 2, as.numeric))  

sapply(df_chars_as_num, class) 
```

```{r}
# Dropping the label (revenue column) 
df2 = subset(df, select = -c(Weekend , Revenue,VisitorType,Month))

str(df2)

```

```{r}
#Implementing the hierarchical clustering algorithm
# Scaling our data
df2 <- scale(df2)
head(df2)

```

```{r}

d <- dist(df2, method = "euclidean")
```

```{r}
# Fitting the hierarchical clustering using the Ward's method
# ---
# 
res.hc <- hclust(d, method = "ward.D2")
```

```{r}
# plotting the dendrogram
# ---
# 
plot(res.hc, cex = 0.6, hang = -1)
```
The clusters are many and are overlapping due to the large dataset thus the dendogram is not legible making it difficult to make any deductions.

## k-Means Clustering
```{r}
# Modeling packages
library(cluster)     # for general clustering algorithms
library(factoextra)  # for visualizing cluster results
```

```{r}
# Loading package
library(ClusterR)
library(cluster)
```

```{r}
# determining optimal number of clusters
fviz_nbclust(df2, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2)


# The optimal number of clusters is 4.
```


```{r}
# Applying K-means with K=4

set.seed(123)
result <- kmeans(df2, 4, nstart = 25)
```


```{r}
# Previewing the no. of records in each cluster
result$size
```


```{r}
# cluster means
result$centers
```


```{r}
# plotting the clusters(factorextra package)
fviz_cluster(result, data = df2)

```
All the cluster are slightly overlapping.Cluster 3 has a slightly higher concentration of the data groups. 

# Conclusion and recommendations
Comparatively, the k-means clusters are visually clearer thus we recommend the customer to apply the k-means algorithm for customer analysis. Since the data set is large(more than 500 observations), k-means will also be most appropriate because hierarchical clustering does not work well with large datasets.




